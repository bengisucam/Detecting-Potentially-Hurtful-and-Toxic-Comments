{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import   TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classes=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "df=pd.read_csv('./Data/train.csv')\n",
    "\n",
    "train, test = train_test_split(df, random_state=4, test_size=0.25, shuffle=True)\n",
    "summary=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                     id                                       comment_text  \\\n92960  f88f17ce73d55ad9  Mark Teixiera\\nPer WP:CRYSTAL, we only change ...   \n39944  6a9f4af6d51fc9e2  \"\\n\\n Reblock \\n\\nReblock that IP you unblocke...   \n73371  c44f6d09834d1058  \"::::Censorship isn't an answer. Some things s...   \n\n       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n92960      0             0        0       0       0              0  \n39944      0             0        0       0       0              0  \n73371      0             0        0       0       0              0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>92960</th>\n      <td>f88f17ce73d55ad9</td>\n      <td>Mark Teixiera\\nPer WP:CRYSTAL, we only change ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39944</th>\n      <td>6a9f4af6d51fc9e2</td>\n      <td>\"\\n\\n Reblock \\n\\nReblock that IP you unblocke...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73371</th>\n      <td>c44f6d09834d1058</td>\n      <td>\"::::Censorship isn't an answer. Some things s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "X_train = train.comment_text\n",
    "X_test = test.comment_text\n",
    "summary+=\"Train Samples: {}\\nTest Samples: {}\\n\\n\".format(len(X_train),len(X_test))\n",
    "test.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Multinomial Naive Bayes': Pipeline(memory=None,\n          steps=[('vect',\n                  TfidfVectorizer(analyzer='word', binary=False,\n                                  decode_error='strict',\n                                  dtype=<class 'numpy.float64'>,\n                                  encoding='utf-8', input='content',\n                                  lowercase=True, max_df=1.0, max_features=None,\n                                  min_df=1, ngram_range=(1, 1), norm='l2',\n                                  preprocessor=None, smooth_idf=True,\n                                  stop_words=frozenset({'a', 'about', 'above',\n                                                        'across', 'after',\n                                                        'afterwards...\n                                                        'amongst', 'amoungst',\n                                                        'amount', 'an', 'and',\n                                                        'another', 'any',\n                                                        'anyhow', 'anyone',\n                                                        'anything', 'anyway',\n                                                        'anywhere', ...}),\n                                  strip_accents=None, sublinear_tf=False,\n                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                  tokenizer=None, use_idf=True,\n                                  vocabulary=None)),\n                 ('clf',\n                  OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0,\n                                                              class_prior=None,\n                                                              fit_prior=True),\n                                      n_jobs=None))],\n          verbose=True), 'Support Vector Machine': Pipeline(memory=None,\n          steps=[('vect',\n                  TfidfVectorizer(analyzer='word', binary=False,\n                                  decode_error='strict',\n                                  dtype=<class 'numpy.float64'>,\n                                  encoding='utf-8', input='content',\n                                  lowercase=True, max_df=1.0, max_features=None,\n                                  min_df=1, ngram_range=(1, 1), norm='l2',\n                                  preprocessor=None, smooth_idf=True,\n                                  stop_words=frozenset({'a', 'about', 'above',\n                                                        'across', 'after',\n                                                        'afterwards...\n                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                  tokenizer=None, use_idf=True,\n                                  vocabulary=None)),\n                 ('clf',\n                  OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200,\n                                                    class_weight=None, coef0=0.0,\n                                                    decision_function_shape='ovr',\n                                                    degree=3, gamma='auto',\n                                                    kernel='sigmoid',\n                                                    max_iter=-1,\n                                                    probability=False,\n                                                    random_state=None,\n                                                    shrinking=True, tol=0.001,\n                                                    verbose=False),\n                                      n_jobs=None))],\n          verbose=True), 'Decision Tree': Pipeline(memory=None,\n          steps=[('vect',\n                  TfidfVectorizer(analyzer='word', binary=False,\n                                  decode_error='strict',\n                                  dtype=<class 'numpy.float64'>,\n                                  encoding='utf-8', input='content',\n                                  lowercase=True, max_df=1.0, max_features=None,\n                                  min_df=1, ngram_range=(1, 1), norm='l2',\n                                  preprocessor=None, smooth_idf=True,\n                                  stop_words=frozenset({'a', 'about', 'above',\n                                                        'across', 'after',\n                                                        'afterwards...\n                                  vocabulary=None)),\n                 ('clf',\n                  OneVsRestClassifier(estimator=DecisionTreeClassifier(class_weight=None,\n                                                                       criterion='gini',\n                                                                       max_depth=4,\n                                                                       max_features=None,\n                                                                       max_leaf_nodes=None,\n                                                                       min_impurity_decrease=0.0,\n                                                                       min_impurity_split=None,\n                                                                       min_samples_leaf=1,\n                                                                       min_samples_split=2,\n                                                                       min_weight_fraction_leaf=0.0,\n                                                                       presort=False,\n                                                                       random_state=None,\n                                                                       splitter='best'),\n                                      n_jobs=None))],\n          verbose=True)}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "clf_multinomial_bayes = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)),\n",
    "        ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None))),\n",
    " ],verbose=True)\n",
    "clf_decision_tree = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)),\n",
    "        ('clf', OneVsRestClassifier(DecisionTreeClassifier(max_depth=4))),\n",
    " ],verbose=True)\n",
    "\n",
    "clf_svm = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)),\n",
    "        ('clf', OneVsRestClassifier(SVC(gamma='auto',kernel='sigmoid'))),\n",
    " ],verbose=True)\n",
    "\n",
    "classifiers={'Multinomial Naive Bayes':clf_multinomial_bayes,'Support Vector Machine':clf_svm,'Decision Tree':clf_decision_tree}\n",
    "classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_overall_accuracy(test_df):\n",
    "    all_corrects=0\n",
    "    for row in range(len(test_df)):\n",
    "        current_row=test_df.iloc[row]\n",
    "        wrong=False\n",
    "        for label in classes:\n",
    "            if current_row[label] != current_row['predicted_'+label]:\n",
    "                wrong=True\n",
    "                break\n",
    "        if not wrong:\n",
    "            all_corrects+=1\n",
    "    return all_corrects/len(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "For classifier Multinomial Naive Bayes\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   5.6s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Accuracy for class 'toxic' is: 0.9215401198205199\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   5.9s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.0s\n",
      "Accuracy for class 'severe_toxic' is: 0.9902739829042689\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   5.6s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Accuracy for class 'obscene' is: 0.9517960544456421\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   6.1s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Accuracy for class 'threat' is: 0.9973930263454741\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   6.3s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Accuracy for class 'insult' is: 0.9530744742185345\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   6.6s\n[Pipeline] ............... (step 2 of 2) Processing clf, total=   0.1s\n",
      "Accuracy for class 'identity_hate' is: 0.9912014639159752\n",
      "For classifier Support Vector Machine\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   6.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total= 8.1min\n",
      "Accuracy for class 'toxic' is: 0.9035169077281728\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   5.6s\n",
      "[Pipeline] ............... (step 2 of 2) Processing clf, total=  37.5s\n",
      "Accuracy for class 'severe_toxic' is: 0.9902990499586394\n",
      "[Pipeline] .............. (step 1 of 2) Processing vect, total=   5.6s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for each_clf in classifiers:\n",
    "    print(\"For classifier {}\".format(each_clf))\n",
    "    copy_test=test.copy()\n",
    "    overall_acc=0.0\n",
    "    for each_class in classes:\n",
    "        clf=classifiers[each_clf]\n",
    "        clf.fit(X_train,train[each_class])\n",
    "        predicted = clf.predict(X_test)\n",
    "        \n",
    "        copy_test['predicted_'+each_class]=predicted\n",
    "        \n",
    "        ind_cor_rate=np.mean(predicted == test[each_class])\n",
    "        overall_acc+=ind_cor_rate\n",
    "        summary+=\"Rate of '{}' classifier for class '{}' is {}\\n\".format(each_clf,each_class,ind_cor_rate)\n",
    "        print(\"Accuracy for class '{}' is: {}\".format(each_class,ind_cor_rate))\n",
    "    \n",
    "    overall_acc/=len(classes)\n",
    "    summary+='\\nOverall class accuracy is {}\\n'.format(overall_acc)\n",
    "    summary+='Overall all class accuracy for classifier {} is {}\\n\\n'.format(each_clf,get_overall_accuracy(copy_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save txt\n",
    "summary_out = open(\"summary.txt\", \"w\")\n",
    "summary_out.write(summary)\n",
    "summary_out.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}