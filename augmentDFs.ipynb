{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/3   Reading File...]\n",
      "[Step 2/3   Cleaning data...]\n",
      "[Step 3/3   Sampling data...]\n",
      "\n",
      "Sample 1: \n",
      " the order of the arrow is a topic like any other wikipedia editors are under no obligation to adhere to the rules of any organization in terms of what information about said organization may be made public in the relevant article moreover if the information is coming from a credible source in this case the recognized texts of the organization itself by what right do other editors refute that information validity in looking at the personal pages of the editors who have insisted on the exclusion of oa secrets over the life of this article it is clear that they are themselves members since oa members are under obligation to keep this information secret it is untenable that they should be permitted to control the editorial process of this entry and to put blocks on editors who do agree with them\n",
      "Sample 2: \n",
      " anyways i am not here to discuss the screwed up concept of race in other countries but the reality of dr the concensus here among dominicans is that the 90% african decent is a vague statement people that claim other heritages mixed want to be classified as mixed in the case of dr as mulattoes because they do view themselves racially different from the sammy sosa type dominicans platanogeniusx link title http wwwhoycomdo articleaspx&id;18092 link title\n",
      "Sample 3: \n",
      "i do not get your point could you please elaborate are you referring to the verses of hindu scriptures that i added if so then i would like to inform you that the subject of the article is implicitly about the massive animal sacrifice done in the name of hinduism the article does not focus on anything else i did not only cite the scriptures but also other sources that purports to tell what is the real story behind the origin of gadhimai festival i did not claim it as the sole truth either but it provided a food for thought if according to you that is original research then everything is original research wo not you say if not in the gadhimai festival article then where should we give a chance to hinduism as a religion of non violence the article attributes all the animal killings of the festival to hinduism is not that a sufficient ground to shed light on the religion actual position besides the animal killings of the festival are associated to hinduism but based on what is not that an original research or a subject of personal opinion too thank you i await your reply talk\n",
      "Sample 4: \n",
      "it just goes to show stupid mario was btw raintheone well done but as i said above that just is not enough to stop me;\n",
      "Sample 5: \n",
      " i hope you enjoy editing here and being a wikipedian please sign your name on talk pages using four tildes ~~~~; this will automatically produce your name and the date if you need help check out wikipedia where to ask a question ask me on my talk page or place helpme on your talk page and someone will show up shortly to answer your questions again welcome  afist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     C:\\Users\\bengi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"word 'd' not in vocabulary\"\n",
      "\"word 'aww' not in vocabulary\"\n",
      "\"word 'colour' not in vocabulary\"\n",
      "\"word '' not in vocabulary\"\n",
      "\"word '' not in vocabulary\"\n",
      "\"word 'january' not in vocabulary\"\n",
      "\"word '' not in vocabulary\"\n",
      "\"word '' not in vocabulary\"\n",
      "\"word 'utc' not in vocabulary\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d aww he match the backgrounds colour u noon seemingly sticking having thanks talking   january   utc'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### bu cell main in aynısı ####\n",
    "import pandas\n",
    "import packages.text.textutilities as utilities\n",
    "from packages.text.skeleton import Skeleton\n",
    "import packages.classification.classifier as clfs\n",
    "import packages.augmentation.embedding as embeddings\n",
    "\n",
    "categories=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "df=pandas.read_csv('./Data/train.csv')\n",
    "\n",
    "skeleton=Skeleton()\n",
    "skeleton.build([\n",
    "    utilities.clean_text,\n",
    "    utilities.sample\n",
    "],df_path='./Data/train.csv')\n",
    "\n",
    "\n",
    "word2vec_model=embeddings.EmbeddingAugmentation(load_path=None) #\"./word2vec/word2vec.model\"\n",
    "word2vec_model.replace_sentence_with_top(skeleton.text[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = df.index\n",
    "columns = list(df.columns)\n",
    "values = df.values\n",
    "\n",
    "\n",
    "def createAndAugmentDFs(df):\n",
    "    \n",
    "    to,se,ob,th,ins,ha = 0,0,0,0,0,0\n",
    "    \n",
    "    to_list = []\n",
    "    se_list = []\n",
    "    ob_list = []\n",
    "    th_list = []\n",
    "    ins_list = []\n",
    "    ha_list = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        comment = df.iloc[i:i+1]\n",
    "        comment_id = comment[\"id\"]\n",
    "        comment_text = comment[\"comment_text\"]\n",
    "        is_toxic =  int(comment[\"toxic\"])\n",
    "        is_severe = int(comment[\"severe_toxic\"])\n",
    "        is_obscene = int(comment[\"obscene\"])\n",
    "        is_threat = int(comment[\"threat\"])\n",
    "        is_insult = int(comment[\"insult\"])\n",
    "        is_hate = int(comment[\"identity_hate\"])\n",
    "        \n",
    "        if(is_toxic):\n",
    "            to_list.append(comment_text)\n",
    "        if(is_severe):\n",
    "            se_list.append(comment_text)\n",
    "        if(is_obscene):\n",
    "            ob_list.append(comment_text)\n",
    "        if(is_threat):\n",
    "            th_list.append(comment_text)\n",
    "        if(is_insult):\n",
    "            ins_list.append(comment_text)\n",
    "        if(is_hate):\n",
    "            ha_list.append(comment_text)\n",
    "        \n",
    "    \n",
    "    toxic_df = pandas.DataFrame(to_list)\n",
    "    severe_df = pandas.DataFrame(se_list)\n",
    "    obscene_df = pandas.DataFrame(ob_list)\n",
    "    threat_df = pandas.DataFrame(th_list)\n",
    "    insult_df = pandas.DataFrame(ins_list)\n",
    "    hate_df = pandas.DataFrame(ha_list)\n",
    "    \n",
    "    return toxic_df,severe_df,obscene_df,threat_df,insult_df,hate_df\n",
    "    \n",
    "\n",
    "toxic_df,severe_df,obscene_df,threat_df,insult_df,hate_df = createAndAugmentDFs(df)\n",
    "\n",
    "print(toxic_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
