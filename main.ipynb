{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import packages.text.textutilities as utilities\n",
    "from packages.text.skeleton import Skeleton\n",
    "import packages.augmentation as augmentation\n",
    "import packages.estimation as estimation\n",
    "import packages.classification.classifier as clfs\n",
    "\n",
    "categories=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "df=pandas.read_csv('./Data/train.csv')\n",
    "print(len(df[df['toxic']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[Step 1/5   Reading File...]",
      "\n",
      "[Step 2/5   Sampling data...]\n\nSample 1: \n\"\n\nSameerKhan, Antorjal etc. have not been on SJSA page nor do they probably care either. You still forget that DaGizza, Basawala (himself an Urdu user) and Anupam (Urdu speaker) have provided more than enough proof to cement the use of Hindi. Its very much a dispute because you tried it on VM and JGM (where the Bengali users agreed to consensus) and now on SJSA. Calling Dagizza, basawala, mahawiki, me, and anupam (three different religions, three different languages) a consensus by \"\"mob\"\". Ragib probably totally forgot about the page, its not like he (or SameerKhan) cares about you and mahawiki duking it out. Bakatalk \"\nSample 2: \nI like the example given on the following post - http://theautomaticearth.blogspot.com/2011/07/july-28-2011-real-black-real-swan.html 167.30.73.70\nSample 3: \nThis article has already been deleted at least twice. It was previously deleted by AfD, Wikipedia:Articles for deletion/Plastic Paddies, has been reposted and speedied at least once, possibly twice IIRC. Speedy delete it with prejudice and salt Plastic Paddy, Plastic paddy, Plastic Paddies, and Plastic paddies. - (Talk)\nSample 4: \n\"\n\nWhat is now the type specimen of T rex?\n\"\"Manospondylus controversy\"\" has an image whose caption says \"\" ... type specimen ... inaccurately reconstructed ... now disassembled.\"\" So what is now the the type specimen of T rex? Should we revise \"\"Classification\"\" to identify the current type specimen (preferably with image)?   \"\nSample 5: \nIvan Moffat\nHi and thanks for your message. Have looked at the site where I obtained the image and it has been removed. It is therefore perfectly possible that the image is not Ivan Moffat so I would support its being removed. Thanks\n[Step 3/5   Cleaning data...]\n",
      "[Step 4/5   Trimming data...]\n\n",
      "[Step 5/5   Sampling data...]\n\nSample 1: \nbye do not look come or think of comming back tosser\nSample 2: \nactually anti zionism is a form of racism since zionism is the liberation of the jewish people from islamic oppression supporting palestinians is also racism because they are arabian colonists and imperialists â€” preceding unsigned comment added by\nSample 3: \nhow was that a personal attack he was being a dick so it was fair cop to call him one\nSample 4: \nimpact speed is impossible the discovery section cites without attribution that the impactor speed was  thousand miles per hour this is approximately  km per second far in excess of the approximately  km per second that is the maximum impact speed a solar system object can have with the earth\nSample 5: \nnice to know you back nazi\n159571\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "skeleton=Skeleton()\n",
    "skeleton.build([\n",
    "    utilities.sample,\n",
    "    utilities.clean_text,\n",
    "    utilities.trim_corpus,\n",
    "    utilities.sample\n",
    "],df_path='./Data/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "159571\n144277\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(skeleton.data_size)\n",
    "print(len(skeleton.df[skeleton.df['toxic']==0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[Classifier 1/4   Fitting data over Average of SVM, Naive Bayes and Decision Tree...]\n",
      "  Category #1: toxic \n    Accuracy is 0.9029\n    Total correct classifications is 9029\n    Total test data size is 10000\n  Category #2: severe_toxic \n    Accuracy is 0.9899\n    Total correct classifications is 9899\n    Total test data size is 10000\n  Category #3: obscene \n    Accuracy is 0.9473\n    Total correct classifications is 9473\n    Total test data size is 10000\n  Category #4: threat \n    Accuracy is 0.9967\n    Total correct classifications is 9967\n    Total test data size is 10000\n  Category #5: insult \n    Accuracy is 0.9506\n    Total correct classifications is 9506\n    Total test data size is 10000\n  Category #6: identity_hate \n    Accuracy is 0.9916\n    Total correct classifications is 9916\n    Total test data size is 10000\n\n[Classifier 2/4   Fitting data over Decision Tree...]\n",
      "  Category #1: toxic \n    Accuracy is 0.9311\n    Total correct classifications is 9311\n    Total test data size is 10000\n  Category #2: severe_toxic \n    Accuracy is 0.9915\n    Total correct classifications is 9915\n    Total test data size is 10000\n  Category #3: obscene \n    Accuracy is 0.9734\n    Total correct classifications is 9734\n    Total test data size is 10000\n  Category #4: threat \n    Accuracy is 0.9984\n    Total correct classifications is 9984\n    Total test data size is 10000\n  Category #5: insult \n    Accuracy is 0.9652\n    Total correct classifications is 9652\n    Total test data size is 10000\n  Category #6: identity_hate \n    Accuracy is 0.9936\n    Total correct classifications is 9936\n    Total test data size is 10000\n\n[Classifier 3/4   Fitting data over Naive Bayes...]\n",
      "  Category #1: toxic \n    Accuracy is 0.9137\n    Total correct classifications is 9137\n    Total test data size is 10000\n  Category #2: severe_toxic \n    Accuracy is 0.9899\n    Total correct classifications is 9899\n    Total test data size is 10000\n  Category #3: obscene \n    Accuracy is 0.9507\n    Total correct classifications is 9507\n    Total test data size is 10000\n  Category #4: threat \n    Accuracy is 0.9967\n    Total correct classifications is 9967\n    Total test data size is 10000\n  Category #5: insult \n    Accuracy is 0.9507\n    Total correct classifications is 9507\n    Total test data size is 10000\n  Category #6: identity_hate \n    Accuracy is 0.9916\n    Total correct classifications is 9916\n    Total test data size is 10000\n\n[Classifier 4/4   Fitting data over SVM...]\n",
      "  Category #1: toxic \n    Accuracy is 0.9029\n    Total correct classifications is 9029\n    Total test data size is 10000\n  Category #2: severe_toxic \n    Accuracy is 0.9899\n    Total correct classifications is 9899\n    Total test data size is 10000\n  Category #3: obscene \n    Accuracy is 0.9473\n    Total correct classifications is 9473\n    Total test data size is 10000\n  Category #4: threat \n    Accuracy is 0.9967\n    Total correct classifications is 9967\n    Total test data size is 10000\n  Category #5: insult \n    Accuracy is 0.9506\n    Total correct classifications is 9506\n    Total test data size is 10000\n  Category #6: identity_hate \n    Accuracy is 0.9916\n    Total correct classifications is 9916\n    Total test data size is 10000\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "skeleton.classify([\n",
    "    clfs.AveragingEstimator(),\n",
    "    clfs.DecisionTree(),\n",
    "    clfs.NaiveBayes(),\n",
    "    clfs.SVM(),\n",
    "    \n",
    "],keys=categories)\n",
    "\n",
    "skeleton.save_progress(\"progress.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "}}{{Connected contributor|WWB Too|WWB Too|editedhere=no\nconnected contributor wwb too wwb too editedhereno\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "utilities.clean_sample(\"}}{{Connected contributor|WWB Too|WWB Too|editedhere=no\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}