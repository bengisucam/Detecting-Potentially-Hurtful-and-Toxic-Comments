{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from packages.text.textutilities import *\n",
    "from packages.text.skeleton import Skeleton\n",
    "import packages.classification.classifier as clfs\n",
    "import packages.augmentation.embedding as embeddings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "categories=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "random_state=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[Step 1/2   Cleaning data...]\n",
      "[Step 2/2   Sampling data...]\nSample 1: \njust look at what this fucktard future perfect at sunrise gave me as a reason he said i was banned persistent disruptive editing move warring copy and paste moves personal attacks tendentious editing personal attacks and who the fuck done a personal attack i ve never made a personal attack on here and i have been in here for nearly  years and i only bash on u cause u son of bitch blocked me for no reason tendentious editing is totally a false accusation now fuck off future perfect at sunrise and ur henchman\nSample 2: \nit khoikhoi that sock is mr putnam alias khoikhoi i am also jew but this hungarian jew is an anti romanian one\nSample 3: \nhi noah thanks for your reply i have found most of the answers to my questions on that lhc website quoted earlier link and for other questions i ve visited physicsforum i agree there is a safety issue to the lhc as imho the reference for cosmic rays is not water tight and we are surpassing the energies of normal cosmic rays setting off violent sparks in a lively environment greetings\nSkeleton build is done!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build a skeleton framework to ease up workflow\n",
    "\"\"\"\n",
    "skeleton=Skeleton(categories,random_state)\n",
    "skeleton.build([\n",
    "    TextCleaner(),\n",
    "    Sampler()\n",
    "    # Trimmer(threshold=12)\n",
    "],df_path='./Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "toxic\nsevere_toxic\nobscene\nthreat\ninsult\nidentity_hate\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "'toxic: 15294 samples\\nsevere_toxic: 1595 samples\\nobscene: 8449 samples\\nthreat: 478 samples\\ninsult: 7877 samples\\nidentity_hate: 1405 samples\\n'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "skeleton.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-10a4f3e37353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mGet\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mn_category\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meach\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_by_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Detecting-Potentially-Hurtful-and-Toxic-Comments/packages/text/skeleton.py\u001b[0m in \u001b[0;36msplit_by_keys\u001b[0;34m(self, n_category)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdf_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mdf_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4968\u001b[0m             )\n\u001b[1;32m   4969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4970\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4971\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ],
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get <n_category> random samples from each category\n",
    "\"\"\"\n",
    "samples=skeleton.split_by_keys(n_category=3000)\n",
    "samples['toxic']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loading Custom Model!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "'will you provide another url if which policy talk page nowhere it seems told if but ve when read but yourself'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "word2vec_model=embeddings.EmbeddingAugmentation(load_path=\"./word2vec/word2vec.model\")\n",
    "word2vec_model.augment_single(\"could you produce a link to the policy page where that is said please i have never read it myself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "BOOSTING_CLASSIFIER_COUNT=100\n",
    "\n",
    "# \n",
    "# skeleton.classify([\n",
    "#     clfs.AdaBoostSVM(n_estimators=2),\n",
    "#     clfs.AdaBoostNaiveBayes(n_estimators=10),\n",
    "#     clfs.AdaBoostNaiveBayes(n_estimators=20),\n",
    "#     clfs.AdaBoostDecisionTree(n_estimators=20),\n",
    "#     clfs.DecisionTree(),\n",
    "#     clfs.NaiveBayes(),\n",
    "#     clfs.AveragingEstimator(),\n",
    "#     clfs.SVM(),\n",
    "#     \n",
    "# ])\n",
    "# \n",
    "# skeleton.save_progress(\"progress.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}